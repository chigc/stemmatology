{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63074545-1567-4a35-92d3-a6bde9ea0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collatex import *\n",
    "import graphviz\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "inputfile=\"input_xml/Sammeltranskripte.xml\"\n",
    "txtpath=\"txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097bf13-438d-424b-a82c-7b8e67a9443e",
   "metadata": {},
   "source": [
    "Options to normalize text and generate Dictionary with plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff407017-7543-4bc2-861f-624c6128c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove leading and trailing whitespaces\n",
    "    text = text.strip()\n",
    "    # Remove double whitespaces\n",
    "    text = \" \".join(text.split())\n",
    "    # Remove linebreaks\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    # to lowercase\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[\\s+]\", \" \", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = text.strip() \n",
    "    return text\n",
    "    \n",
    "def input_to_dict(file):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    # Create a dictionary to store the extracted text\n",
    "    transcript_dict = {}\n",
    "    # Find all <div> elements with attribute type=\"transcript\"\n",
    "    \"\"\" div_elements = root.findall('.//div[@type=\"transcript\"]') \"\"\"\n",
    "    ms = root.findall('.//div[@type=\"ms\"]')\n",
    "    for m in ms:\n",
    "        ms_id = m.attrib['corresp'].replace(\"-\",\"\")\n",
    "        #print (ms_id)\n",
    "        divs = m.findall('.//div[@type=\"transcript\"]')\n",
    "        alltranscripts=\"\"\n",
    "        for div in divs:\n",
    "            alltranscripts += \"\".join(div.find('p').itertext())\n",
    "            alltranscripts += \" \"\n",
    "            # Get the ID of the transcript\n",
    "            transcript_id = div.attrib['corresp'].replace(\"-\",\"\")\n",
    "            #print(transcript_id)\n",
    "            # Get the text of the transcript\n",
    "            transcript_text = \"\".join(div.find('p').itertext())\n",
    "            #print(transcript_text.replace('  ', '')) \n",
    "            # Add the text to the dictionary\n",
    "            transcript_dict[\"_\".join([transcript_id, ms_id])] = [transcript_id ,clean_text(transcript_text)]\n",
    "        #transcript_dict[ms_id] = clean_text(alltranscripts)\n",
    "        #print(alltranscripts)\n",
    "        transcript_dict[\"_\".join([ms_id])] = [\"all\" ,clean_text(alltranscripts)]\n",
    "    return transcript_dict\n",
    "dict = input_to_dict(inputfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b2db5d-f222-4cdc-92d0-e6429602fd6e",
   "metadata": {},
   "source": [
    "Save plaintext to .txt files in txt folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc12553-7549-47d5-841d-7ad0c09ee238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_files(transcript_dict):\n",
    "    # Save the transcript_dict into individual files\n",
    "    for key, value in transcript_dict.items():\n",
    "        filename = f\"{key}.txt\"\n",
    "        folder = txtpath+\"/\"+ value[0]+\"/\"\n",
    "        \n",
    "        mypath = ...\n",
    "        if not os.path.isdir(folder):\n",
    "           os.makedirs(folder)\n",
    "        path =  folder +filename\n",
    "        if value[1] != \"\" and value[1] != \" \":\n",
    "            with open(path, 'w') as file:\n",
    "                file.write(value[1])\n",
    "save_to_files(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a606b8c-be34-4669-a2de-95b2f37c5c60",
   "metadata": {},
   "source": [
    "Start Collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4336fb-88c4-4a33-a3e4-c530b86b9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "collation = Collation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c98820-e39e-4087-9541-365fa2c46684",
   "metadata": {},
   "source": [
    "*Read files in 'txt' folder.*\n",
    "Load content of each file as a witness into collateX with the filename as witness_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c1280a-1fe1-4c70-a0f0-bf191c990845",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"txt/all\"\n",
    "\n",
    "# Initialize a dictionary to store the file contents\n",
    "file_contents = {}\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    #print(filename)\n",
    "    if filename.endswith('.txt'):\n",
    "        # Read the content of the file\n",
    "        with open(os.path.join(directory, filename), 'r') as file:\n",
    "            content = file.read()\n",
    "            #print(content)\n",
    "            # Use filename as variable name and store content as value\n",
    "            file_contents[filename] = content\n",
    "\n",
    "# Now you have a dictionary where keys are filenames and values are file contents\n",
    "# You can also create variables for each file if needed\n",
    "for filename, content in file_contents.items():\n",
    "    #globals()[filename.split('.')[0]] = content\n",
    "    #print(filename.split('.')[0])\n",
    "    collation.add_plain_witness(filename.split('.')[0],content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20d4baf-708a-4537-9810-c483acd47840",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_table = collate(collation, near_match=True, segmentation=False, layout=\"horizontal\")\n",
    "#print(alignment_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1a2c94-5e1e-4e42-a350-4a8936d68949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collate(collation, output='svg_simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ff0e2d-4716-492a-abc5-b29317ea7329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#collate(collation, output=\"html\", layout=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbcdced7-f0bd-4236-acec-bb977bc5a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_csv = collate( collation, near_match=False, output=\"csv\", segmentation=True )\n",
    "with open( 'alignment_alltexts_nearmatch.csv', 'w' ) as csv_file:\n",
    "    csv_file.write( alignment_csv )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c749e69-c3bd-40d0-8673-d6a0971549fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Next Step: Use cx2vartab.py and vartab2nex.py to convert .csv to .nex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a929aa8-d734-4f25-9b7a-a8613ac10f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd661b-dbf1-4017-b15d-7fea8dbfd178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
